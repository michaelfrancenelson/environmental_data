---
title: "ECo 634 - Analysis of Environmental Data Lab"
subtitle: "Simulation and Power Analysis"
author: "Michael France Nelson (adaped from Kevin McGarigal)"
date: "Fall 2020"
output:
  # pdf_document:
  #   toc: true
  #   number_sections: TRUE
  html_document:
    theme: readable
    css: !expr here::here("formatting", "css", "styles.css")
    toc: TRUE
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
require(here)
knitr::opts_chunk$set(echo = TRUE)

require(here)
require(rmd.utils)
require(mfn.teaching.utils)
knitr::opts_chunk$set(echo = TRUE)
```

```{r linear_function, echo = FALSE, eval=FALSE}
linear = function(x, y_int, slope) { return (y_int + x * slope)}
```

```{r linear_simulator_function, echo = FALSE}
linear_simulator = function(x, y_int, slope, st_dev)
{
  linear = function(x, y_int, slope) { return (y_int + x * slope)}
  return(rnorm(n = length(x), mean = linear(x, y_int, slope), sd = st_dev))
}
```

```{r read_bird_data, echo = FALSE}
birds = read.csv(here::here("data", "bird.sub.csv"), header = TRUE)
hab = read.csv(here::here("data", "hab.sub.csv"), header = TRUE)
birdhab = merge(hab, birds, by = c('basin', 'sub'))
```
```{r fit_model_1, echo = FALSE, eval = FALSE}
fit_1 = lm(BRCR~ls, data = birdhab)
```
```{r get_coefficients_sigma, echo = FALSE, eval = FALSE}
fit_1_summary = summary(fit_1)
fit_1_summary$sigma
```


```{r scatterplot_1, echo = FALSE, eval = FALSE}
plot(
  birdhab$ls, birdhab$BRCR, 
  xlab = "late-successional forest extent",
  ylab = "Brown Creeper abundance",
  pch = 19)
```


```{r scatterplot_2, echo = FALSE, eval = FALSE}
plot(
  birdhab$ls, birdhab$BRCR, 
  xlab = "late-successional forest extent",
  ylab = "Brown Creeper abundance",
  pch = 19)
abline(fit_1)
knitr::kable(coef(summary(fit_1)), digits = c(4, 4, 3, 4))
```

```{r effect_size_simulation_save_file, eval = FALSE, echo = FALSE}
alpha = 0.05
n_sims = 500
p_vals = numeric(n_sims)
n_effect_sizes = 80
effect_sizes = seq(from = -0.01, to = 0.01, length.out = n_effect_sizes)
effect_power = numeric(length(effect_size))

for(j in 1:length(effect_sizes))
{
  for(i in 1:n_sims)
  {
    fit_sim = linear_sim_fit(
      x = birdhab$ls,
      y_int = int_obs,
      slope = effect_sizes[j],
      st_dev = sd_obs
    )
    
    p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
  }
  
  effect_power[j] = sum(p_vals < alpha) / n_sims
}

plot(
  effect_sizes, effect_power, 
  type = 'l', xlab = 'Effect size', ylab = 'Power')
abline(v = coef(fit_1)[2], lty = 2, col = 'red')
save(effect_power, file = here::here("data", "sim_output_effect_size.RData"))

```

```{r sample_size_effect_size_simulation_save_file, eval = FALSE, echo = FALSE}
alpha = 0.05
n_sims = 1000
p_vals = numeric(n_sims)
effect_sizes = seq(-.01, .01, by = 0.001)
sample_sizes = seq(10, 50)

sim_output_sample_size_effect_size = matrix(nrow = length(effect_sizes), ncol = length(sample_sizes))

for(k in 1:length(effect_sizes))
{
  effect_size = effect_sizes[k]
  for(j in 1:length(sample_sizes))
  {
    x_vals = seq(0, 100, length.out = sample_sizes[j])
    
    for(i in 1:n_sims)
    {
      fit_sim = linear_sim_fit(
        x = x_vals,
        y_int = int_obs,
        slope = effect_size,
        st_dev = sd_obs
      )
      p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
    }
    sim_output_sample_size_effect_size[k, j] = sum(p_vals < alpha) / n_sims
  }
  print(paste0("computing effect size ", k," of ", length(effect_sizes)))
}
sim_output_sample_size_effect_size = sim_output_2
save(sim_output_sample_size_effect_size, file = here::here("data", "sim_output_sample_size_effect_size.RData"))

image(sim_output_sample_size_effect_size)
```


Analysis of Environmental Data - Stochastic Simulation
(Written by Kevin McGarigal, but borrowed heavily from Ben Bolker (2008))

The purpose of this lab exercise is to introduce you to techniques and ideas related to simulating environmental patterns in R. The main goals are to show you to generate patterns you can use to sharpen your intuition and test your estimation tools, show you how to estimate statistical power by
simulation, and, with an example, illustrate the flexibility of R for simulating environmental patterns and processes.

Of course it is impractical to illustrate the full range of uses of stochastic simulation.

Rather, the intent here is to simply wet your appetite for the great utility of simulation.

Here is an outline of what is included in this lab exercise:


# Data

For this lab, you'll need the data files:

- bird.sub.csv
- hab.sub.csv






# Introduction

## Simulation Modeling

Simulation is sometimes called **forward modeling**, to emphasize that you pick a model and parameters and work forward to predict patterns in the data.

Environmental scientists use simulation to explore what kinds of patterns emerge from proposed models.

Often they use theoretical models without accompanying data, in order to understand qualitative patterns and plan future studies, but simulation is useful even if have data.

You can use simulations to explore the functions and distributions you chose to quantify your data; in other words, to explore possible statistical models for your data.

If you can choose parameters that make the simulated output from those functions and distributions look like your data, you can confirm that the models are reasonable, and simultaneously find a rough estimate of the parameters.

You can use simulated data to test your estimation procedures.

We never know the true answer to an environmental question: we use imperfect measurements and models to get as close to the answer as possible.

- Simulation is a way to test whether you can correctly estimate the parameters of an environmental system.

It's always a good idea to test such a best-case scenario, where you know that the functions and distributions you're using are correct, before you proceed to real data.

There are many different types of simulation models, we'll only cover a couple in this lab.



# Power Analysis

Power analysis using simulation models allows you to explore how different experimental designs and sample sizes might affect your ability to get a reasonably precise estimate of your parameters.

We'll work through an example of a power analysis simulation in the context of a linear regression.


## Simulating Static Environmental Processes: Linear Regression

Static environmental processes, where the data represent a snapshot of some environmental system, are relatively easy to simulate.

Keeping in mind the dual model paradigm, we can specify:

- a deterministic function to simulate the average behavior in our system
- a stochastic model to simulate the variability in the system.

Our determinsitic models might be very simple, for example: a linear function.  

Alternatively we could use any of the more complex mechanistic or phenomenological functions we have studied such as the Ricker or logistic functions.

We could use R's random number generating functions from distributions like the Normal ,`rnorm()`, or Poisson, `rpois()`distributions.


Here we will illustrate the process of simulating a static environmental process using a simple linear regression model based on the now familiar Oregon birds data set.

For this example, let's examine the relationship between brown creeper abundance and the extent of late-successional forest across 30 subbasins in the central Oregon Coast Range.


### Read The Data

You'll need to read the two data files and use `merge()` to combine them into a single `data.frame` object.

You need to merge based on the columns: 'basin', and 'sub'.

- Save the merged data frame to a variable called `birdhab`.
- Your merged data.frame should have the following dimensions:


```{r bird_data_dimensions}
dim(birdhab)
```


### Graphical Exploration

- Create a scatterplot of brown creeper abundance and the extent of late-successional forest:

```{r ref.label="scatterplot_1", echo = FALSE}
```
- Does the relationship look linear?
- Examining the scatterplot, do you see any potential challenges for a Group 1 model?


### Fit a model

Recall that a simple linear regression model can be written symbolically as: $Y ~ Normal(a + bx, \sigma ^2)$

This means that the ith value of Y, $y_i$, is equal to $a + bx_i$ plus a normally distributed error with mean zero and variance $\sigma^2$.

- Fit a simple linear regression using `lm()`.  Save your model as `fit_1`.
- Plot the regression line over the scatterplot using `abline()`.
- Examine the model coefficient table.

```{r ref.label = "fit_model_1", echo = FALSE}
```
```{r ref.label = "scatterplot_2", echo = FALSE}
```

- Does the model suggest a significant relationship between late-successional forest and Brown Creeper abundance?
- Can we say with confidence that it is real or could it be a sampling artifact or a product of chance?

Recall that the data-collection effort was one realization of the stochastic process of sampling.  There are many, many other possible observations that could have been sampled!

- What might the data look like if we were to obtain another snapshot?

This is where stochastic simulation comes in to play.



## Simulator Function

We can simulate the system using our model and see what kind of range of data we might observe.

This can give us great insight into the level of certainty we have in our model.

This is in fact the theoretical basis for the Frequentist approach to statistical inference, in which we evaluate the likelihood of our data given the model, which implicitly means how likely would we observe our original data if we were to repeatedly sample the system.

This is exactly what simulation allows us to do: repeatedly sample the environmental system under the assumption that the model is the truth.



### Components of the model

To generate data based on a Group 1 Simple Linear Regression, what model parts do we need to know?

- Parameters for the deterministic model:
- y-intercept
- slope coefficient
- Parameter for the stochastic model: $\sigma$


#### Deterministic Model: Linear Function

Let's build an R function to calculate the value of a linear function given a value of x, a slope parameter, and an intercept parameter.

Recall the equation for a line: $y = \alpha + \beta x$

- Create an R function, `linear()`, that accepts three named arguments:
1. `x`
2. `y_int`
3. `slope`

- Your function needs to return a single numeric value.
- Your function must be able to handle values of `x` that are single numbers, or numeric vectors.

To test your implementation, you can compare your function's outputs to these reference outputs:

```{r ref.label = "linear_function", echo = FALSE}
```
```{r test_linear_function, results='asis'}
linear(x = 1, y_int = 1, slope = 1)
linear(x = 3:5, y_int = 1, slope = 1)
linear(x = 3:5, y_int = -1, slope = 1)
linear(x = 3:5, y_int = -1, slope = 0.01)
```




#### Stochastic Model: Normal Distribution

This part is easy, it's just `rnorm()` with appropriate arguments for mean and standard deviation!




### Simulation Function

Now you can assemble your deterministic and stochastic functions into a single data simulator.

- Create a function, `linear_simulator()`, that will generate random data based on a linear deterministic function with normally-distributed errors.
- Your function needs to accept the following four named arguments:
1. `x`
2. `y_int`
3. `slope`
4. `st_dev`

There are many approaches your implementation could use.  A simple plan might be:

1. Generate the y-values on the line.
2. Add normally-distributed errors and return.

You are free to implement `linear_simulator()` any way you like...as long as it works correctly!




### Test Your Simulator Function

Since `linear_simulator()` will return different values each time, it's harder to check your implementation.  

For now, you can use a graphical validation approach.

Run the code below and compare your plots to the reference plots:

```{r ref.label = "linear_simulator_function", echo = FALSE}
```

```{r graphical_check_1, fig.asp=1}
n = 200

par(mfrow = c(2, 2))
for (i in 1:4)
{
  x = runif(n = n)
  plot(
    x, linear_simulator(x, 1, 4.5, 0.1),
    main = "", xlab = "x", ylab = "y",
    pch = 16, col = rgb(0, 0.2, 0, 0.2))
}
```


Now compare your implementation to the reference using different slope, intercept, and standard deviation parameters:



```{r graphical_check_2, fig.asp=1}
n = 400

par(mfrow = c(2, 2))
for (i in 1:4)
{
  x = runif(n = n)
  plot(
    x, linear_simulator(x, 10, slope = -6.5, st_dev = 1.1),
    main = "", xlab = "x", ylab = "y",
    pch = 16, col = rgb(0, 0.2, 0, 0.2))
}
```


Your generated data won't be exactly the same as mine, but your plots should look similar to the reference plots in the walkthrough.

<div class="notes">
-NOTE: To properly examine your plots, you might need to save your plots to image files and then open them in an image application.  The plot viewer in RStudio doesn't always handle multi-panel figures gracefully.
</div>




### Build the simulation

#### Retrieve the model coefficients

To simulate new data, you need to retrieve the intercept, slope, and standard deviation from the model you fit to the data.  You can use `coefficients()` to extract the intercept and slope values.  Use `str()` to examine the output of `coefficients()` to 

```{r get_coefficients_1}
fit_1_coefs = coefficients(fit_1)
str(fit_1_coefs)
```

Retrieving the standard deviation parameter is slightly more difficult:

- Create an model summary object using `summary()`.
- The value you want is stored in an element called `sigma`.  You can extract it using the dollar sign.

```{r ref.label = "get_coefficients_sigma"}
```

Store the intercept, slope, and standard deviation parameters from the model into the following variables:

- `int_obs`
- `slope_obs`
- `sd_obs`

```{r model parameters, echo = FALSE}
fit_1_summary = summary(fit_1)
fit_1_coefs = coefficients(fit_1)
str(fit_1_coefs)

sd_obs = fit_1_summary$sigma
int_obs = fit_1_coefs[1]
slope_obs = fit_1_coefs[2]
```




#### Choose Predictor Values

The first goal of the simulation is to generate some new "data" using our model.

We have several options:

- Allow x (the late successional forest extent) vary randomly between 1 and 100.
- Use the observed x values.
- Resample the observed x values.

Any of the approaches are legitimate, so for our purpose, let's keep the original values of x and let brown creeper abundance vary among simulations.



#### Simulate Data

Now that you know the model parameter values and have a strategy for choosing x-values, you can create some sampled Brown Creeper data!


Try running the following code a few times to view different simulation results:

```{r simulated data plot 1}
plot(
  x = birdhab$ls, 
  y = linear_simulator(
    x = birdhab$ls,
    y_int = int_obs,
    slope = slope_obs,
    st_dev = sd_obs
  ),
  main = "Simulated Data",
  xlab = "late-successional forest",
  ylab = "Brown Creeper Abundance")
```


Alternatively, you could plot the observed data first, then add the simulated data to the existing plot:

```{r simulated data plot 2}

plot(
  birdhab$ls, birdhab$BRCR, 
  xlab = "late-successional forest extent",
  ylab = "Brown Creeper abundance",
  pch = 19)


points(
  x = birdhab$ls, 
  y = linear_simulator(
    x = birdhab$ls,
    y_int = int_obs,
    slope = slope_obs,
    st_dev = sd_obs
  ),
  col = adjustcolor("red", alpha = 0.3),
  pch = 16)
```




- Is the new pattern of points the same as the original pattern?
- Are there any notable discrepancies?

You might want to run the model a couple of more times to see how variable the results are.

- After running the model a few times, do you notice any problems with the model?

In other words, does the model reproduce the patterns in the original data perfectly or are there issues with the spread of values or with the generation of illogical values?

One problem with the use of the normal distribution is that it is unbounded on the lower limit.

Thus, negative values are possible.

In this case, because the y-intercept is close to 0, the simulation is likely to produce negative values occasionally when x = 60.

Since brown creeper abundance cannot be negative, this is an undesirable behavior of the model.




# Power analysis for the linear regression model

Power analysis in the narrowest sense means figuring out the (frequentist) statistical power, the probably of correctly rejecting the null hypothesis when it is false.

While we are generally less concerned with power analysis in the conventional sense of hypothesis testing, we are very interested in the role of power analysis in addressing a much broader question:

- How do the quality and quantity of the data and the true properties (parameters) of the environmental system affect the quality and of the answers to our questions about environmental systems?

For any real experiment or observation situation, we don't know what is really going on (the “true” model or parameters), so we don't have the information required to answer these questions from the data alone.

But we can approach them by analysis or simulation.

Historically, questions about statistical power could only be answered by sophisticated analyses, and only for standard statistical models and experimental designs such as one-way ANOVA or linear regression.

Increases in computing power have extended power analysis to many new areas, and R's capability to run repeated stochastic simulations is a great help.

Here, we will illustrate the use of stochastic simulation for power analysis using the linear regression model above.

Let's start by finding out whether we can reject the null hypothesis in a single experiment.

To do this, we simulate a dat set with a given intercept and slope, and number of data points; run a linear regression; extract the p-value (recall, this represents the probability of observing our data if in fact it came from distribution described by the null model, which in this case means that brown creeper abundance is independent of ls or has no relationship to ls); and see whether it is less than our specified alpha criterion (usually 0.05), as follows:

```{r simulated_y_1}
y_sim = linear_simulator(
  x = birdhab$ls,
  y_int = int_obs,
  slope = slope_obs,
  st_dev = sd_obs
)

fit_sim = lm(y_sim ~ birdhab$ls)
summary(fit_sim)$coefficients
# ['x_vals', 'Pr(>|t|)']
```

- Extracting p-values from R analyses can be tricky.

In this case, the coefficients of the summary() of the linear fit are a matrix including the standard error, t statistic, and p-value for each parameter.

I used matrix indexing based on the row and column names to pull out the specific value I wanted.

To estimate the probability of successfully rejecting the null hypothesis when it is false (the power), we have to repeat this procedure many times and calculate the proportion of the time that we reject the null hypothesis.

First, we specify the number of simulations to run and set up a vector to hold the p-value for each simulation.

Then, we repeat what we did above (without redefining some of the objects that have not changed, such as x_vals, a, b, and y.error), each time saving the p-value in the storage vector:

Next, we calculate the power by summing up how many times we rejected the null hypothesis at the specified alpha-level, and dividing by the number of simulations to convert it to a proportion:


```{r p_val_sim}
n_sims = 1000
p_vals = numeric(n_sims)
for(i in 1:n_sims)
{
  y_sim = linear_simulator(
    x = birdhab$ls,
    y_int = int_obs,
    slope = slope_obs,
    st_dev = sd_obs
  )
  fit_sim = lm(y_sim ~ birdhab$ls)
  
  p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
}
sum(p_vals < 0.05) / n_sims
```

- How many simulations found a significant slope coefficient?
- What is our statistical power?

This is the power to detect a slope of roughly b = 0.006 with a sample size of N = 30, given our specified statistical model.

We're going to be building a lot of models, so let's write a quick function to save some time and make our simulation loops a little simpler:

```{r linear_sim_fit}
linear_sim_fit = function(x, y_int, slope, st_dev)
{
  y_sim = linear_simulator(
    x = x,
    y_int = y_int,
    slope = slope,
    st_dev = st_dev
  )
  return(lm(y_sim ~ x))
}
```



### Simulating Effect Sizes

Usually we don't just want to know the power for a single experimental design.

Rather, we want to know how the power changes as we change some aspect of the design such as the sample size or the effect size (slope, in this case).

Thus, we have to repeat the entire procedure multiple times, each time changing some parameter of the simulation such as the slope or the sample size.

Coding this in R usually involves nested “for” loops.

Here is an example to examine how power changes as a function of the slope.  Note that this may take a minute or so to run.


```{r load_effect_size_simulation, echo = FALSE}

load(here::here("data", "sim_output_effect_size.RData"))
effect_sizes = effect_size_sim$effect_sizes
effect_power = effect_size_sim$effect_power

```


```{r effect_size_simulation, echo = TRUE, eval = FALSE}
alpha = 0.05
n_sims = 10
p_vals = numeric(n_sims)
effect_sizes = seq(-.01, .01, by = 0.001)
effect_power = numeric(length(effect_size))

for(j in 1:length(effect_sizes))
{
  for(i in 1:n_sims)
  {
    fit_sim = linear_sim_fit(
      x = birdhab$ls,
      y_int = int_obs,
      slope = effect_size[j],
      st_dev = sd_obs
    )
    
    p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
  }
  effect_power[j] = sum(p_vals < alpha) / n_sims
}

```

Note that this is basically the same function as before, but with the original loop (over simulations) nested within a loop over slope values.

Thus, we needed to create a vector of slope values to evaluate (effect_size) and a storage vector to hold the results (effect_power).

The power is computed for the first value of slope in effect_size (as before) and the result is stored in the first position of the storage vector effect_power.

Each time through the outer loop, a new value of power is computed for the next value of slope.

The result is a vector of power values for increasing values of slope.

We can plot the result and add a vertical line to show the slope of our original data set.


```{r plot_effect_size_sim}
plot(effect_sizes, effect_power, type = 'l', xlab = 'Effect size', ylab = 'Power')
abline(v = coef(fit_1)[2], lty = 2, col = 'red')
```



What is the power for a slope of say .002?

We can do the same thing for a gradient in sample sizes, as follows.



```{r sample_size_simulation, eval = FALSE}
alpha = 0.05
n_sims = 100
p_vals = numeric(n_sims)
sample_sizes = seq(10, 50)
sim_output_1 = numeric(length(sample_sizes))

for(j in 1:length(sample_sizes))
{
  x_vals = seq(0, 100, length.out = sample_sizes[j])
  
  for(i in 1:n_sims)
  {
    fit_sim = linear_sim_fit(
      x = x_vals,
      y_int = int_obs,
      slope = slope_obs,
      st_dev = sd_obs
    )
    p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
  }
  sim_output_1[j] = sum(p_vals < alpha) / n_sims
}

```


```{r load_sampole_size_sim, echo = FALSE}
load(here::here("data", "sim_output_sample_size.RData"))
sim_output_1 = sample_size_sim$sample_powers
sample_sizes = sample_size_sim$sample_sizes
```

```{r sample_size_sim_plot, fig.asp = 1/1.3}

plot(sample_sizes, sim_output_1,  type = 'l', xlab = 'Sample size', ylab = 'Power')
  abline(v = nrow(birdhab), lty = 2, col = 'red')

```



How much power is lost if we reduce the sample size from 30 to 20?

## Simulating Effect Size and Sample Size


We could repeat this process for other parameters such as the error component of the model, but you get the idea.

While we can do these power analysis simulations for one parameter at a time, it might be more interesting to vary combinations of parameters, say of slope and sample size, using yet another loop, saving the results in a matrix, and using contour() or persp() to plot the results.

Try the following:


```{r load_sim_data_1, echo = FALSE}
load(
  file = here::here(
    "data", 
    "sim_output_sample_size_effect_size.RData"))

load(here::here("data", "sim_output_sample_size_effect_size.RData"))

effect_sizes = sim_output_sample_size_effect_size$effect_sizes 
y = sim_output_sample_size_effect_size$sample_sizes
z = sim_output_sample_size_effect_size$data

# image(sim_output_sample_size_effect_size$data)

# contour(
#   x = sim_output_sample_size_effect_size$effect_sizes, 
#   y = sim_output_sample_size_effect_size$sample_sizes, 
#   z = sim_output_sample_size_effect_size$data,
#   xlab = "effect size",
#   ylab = "sample size",
#   main = "Contour Plot of Statistical Power")

```


```{r sample_size_effect_size_simulation, echo = TRUE, eval = FALSE}
alpha = 0.05
n_sims = 10
p_vals = numeric(n_sims)
effect_sizes = seq(-.01, .01, by = 0.001)
sample_sizes = seq(10, 50)

sim_output_2 = matrix(nrow = length(effect_sizes), ncol = length(sample_sizes))

for(k in 1:length(effect_sizes))
{
  effect_size = effect_sizes[k]
  for(j in 1:length(sample_sizes))
  {
    x_vals = seq(0, 100, length.out = sample_sizes[j])
    
    for(i in 1:n_sims)
    {
      fit_sim = linear_sim_fit(
        x = x_vals,
        y_int = int_obs,
        slope = effect_size,
        st_dev = sd_obs
      )
      p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
    }
    sim_output_2[k, j] = sum(p_vals < alpha) / n_sims
  }
}
```

Note, the only difference in this code is that we added a third outer loop and created a matrix to store the results, since we have a power result for each combination of slope and sample size.

- `image()` is a quick way to plot a matrix as if it were raster data, that is to plot a grid in which the pixel color is determined by the value of the matrix element.


```{r}
image(sim_output_2)
```



# Contour plotting

Contour plots are similar to topographic maps.  

The [iso]lines show interpolated lines at which the value is the same.

Let's plot the result using the `contour()` function:

- `contour()` expects arguments for x, y, and z.
- The x- and y- coordinates set up the axes.  In our case we can set the x-axis to be effect size and the y-axis to be sample size.
- the z-coordinates are a matrix in which cells represent the values for which to create the contours.

Use `contour()` to re-create the following figure:


```{r echo = FALSE}
load(
  file = here::here(
    "data", 
    "sim_output_sample_size_effect_size.RData"))

sim_output_2 = sim_output_sample_size_effect_size$data
effect_sizes = sim_output_sample_size_effect_size$effect_sizes
sample_sizes = sim_output_sample_size_effect_size$sample_sizes

```


```{r contour plot, echo=FALSE, fig.asp=1}
contour(
  x = effect_sizes, 
  y = sample_sizes, 
  z = sim_output_2,
  xlab = "effect size",
  ylab = "sample size",
  main = "Contour Plot of Statistical Power",
  levels = seq(0, 1, length.out = 11),
  drawlabels = TRUE,
  # method = "simple")
  method = "edge")
```



# 3D plotting


There are several functions and packages for creating 3D plots in R.

## Perspective Plots

Perspective plots can plot a 3D surface.


### Static Plot

Let's try a static perspective plot using the persp() function, as follows:

```{r persp_plot_static}
persp(
  x = effect_sizes, y = sample_sizes, z = sim_output_2,
  col = 'lightblue',
  theta = 30, phi = 30, expand = .75,
  ticktype = 'detailed')

```

### Interactive Plot

The r package `rgl` allows you to create similar plots that are *interactive*.

- Install `rgl` now so that you can use the `persp3d()` function.

You can use the same syntax as for `persp()` to create a basic interactive plot.

Try it out and see what you get!  

<a href="/eco_602_634_2020/webGL/effect_sample_size_power_sim_plot.html" target="_blank">Click here for an example</a>



```{r persp_plot_interactive, echo = FALSE, eval = FALSE}

rgl::persp3d(
    x = sim_output_sample_size_effect_size$effect_sizes, 
    y = sim_output_sample_size_effect_size$sample_sizes, 
    z = sim_output_sample_size_effect_size$data,
  col = 'lightblue',
    xlab = "effect size",
    ylab = "sample size",
    zlab = "power")

writeWebGL(
  dir = here::here("docs", "webGL"), 
  filename = here::here(
    "docs", "webGL",
    "effect_sample_size_power_sim_plot.html"),
  width = 1200, height = 1200
)
```


# Saving R Data Objects

You may have noticed that some of the simulations take a long time to run!

When you do a simlation study, it is often convenient to save your simulation results so that you don't have to re-run your simulation every time.

You can save R objects to files using `save()`.

- Here's how I could save the results of my effect size and sample size simulation to a file:

```{r save_rdata, eval=FALSE}
save(
  sim_output_2, 
  file = here::here("data", "sample_size_effect_size_power_sim.Rdata"))
```

R saved it to a binary file with the extension ".Rdata".

When I want to load the data again I can use:

```{r load_rdata, eval=FALSE}
load(file = here::here("data", "sample_size_effect_size_power_sim.Rdata"))
```

For the lab exercises, you should save your simulation results to RData files so that you can use them again later without having to re-run the simulations.

NOTE: in the walkthrough examples and code templates I used relatively small numbers of simulations (the nsim variable).  I suggest you use small values as you build your code.  

When your simulations are working as expected, you should increase the number of simulations to something large, 1000 or greater.

You can stage your simulations to run and save the results when you plan to be away from your computer for a while.  Simulation results using lager numbers of iterations will make much smoother curves.



# Conclusions and Exercises

What does the power surface reveal about the relationship between slope and sample size?

If you wanted say a power of >0.8 to detect a slope of b = .002, how large would your sample size need to be?

As you can see, stochastic simulation is an extremely powerful tool for examining power, even in this simple linear regression example where canned approaches exist.

For more complex models, the coding is more complex, but the process is the same. The same basic tools learned in this example can be extended to more complex situations.




## Lab Assignment

We varied the sample and effect sizes to examine statistical power, however we didn't try varying the *dispersion* in the data.

After you complete the lab walkthrough, you will carry out additional power analysis on the data dispersion, i.e. the population standard deviation.




### Population Dispersion Analysis

Review the effect size simulation above.  You will carry out a similar simulation on the population standard deviation instead.

To do the simulation you'll need to:

- Decide the range of population standard deviations to test.
- What was the standard deviation of the residuals from our model?
- I suggest starting with a range of values starting at the observed standard deviation up to 3 times the observed standard deviation.  You will want to experiment with different ranges in order to capture the full picture.


```{r dispersion_simulation_template, eval = FALSE, error=TRUE}
alpha = 0.05
n_sims = 100
p_vals = ...

# What was the observed standard deviation?
sd_obs

# specify the number of different standard deviation values to simulate:
n_sds = 100
pop_sds = seq(from = sd_obs, to = , length.out = n_sds)
pop_sd_power = numeric(...)

for(j in 1:length(pop_sds))
{
  pop_sd_j = pop_sds[j]
  for(i in 1:n_sims)
  {
    fit_sim = linear_sim_fit(
      ...
    )    
    
    p_vals[i] = ...
  }
  pop_sd_power[j] = ...
}

plot(pop_sds, pop_sd_power, type = 'l', xlab = 'Population Standard Deviation', ylab = 'Power')
abline(v = sd_obs, lty = 2, col = 'red')
```



```{r echo = FALSE, eval = FALSE}
alpha = 0.05
n_sims = 10
p_vals = numeric(n_sims)
sd_obs
n_sds = 50
pop_sds = seq(from = 0.1, to = 1.5, length.out = n_sds)
pop_sd_power = numeric(length(pop_sds))

for(j in 1:length(pop_sds))
{
  pop_sd_j = pop_sds[j]
  for(i in 1:n_sims)
  {
    fit_sim = linear_sim_fit(
      x = birdhab$ls,
      y_int = int_obs,
      slope = slope_obs,
      st_dev = pop_sd_j
    )
    
    p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
  }
  pop_sd_power[j] = sum(p_vals < alpha) / n_sims
}

plot(pop_sds, pop_sd_power, type = 'l', xlab = 'Population Standard Deviation', ylab = 'Power')
abline(v = sd_obs, lty = 2, col = 'red')

```

### Population Dispersion and Sample Size Analysis

It looks like statistical power drops off pretty quickly as the population variability increases.

- Could we improve our statistical power with larger sample sizes?


You'll now modify your simulation of population standard deviation to include sample size.


Review the simulation of both sample size and effect size above.

Here's a template for the dispersion and sample size simulation:


```{r dispersion_sample_size_template, echo=TRUE, eval=FALSE}
alpha = 0.05
n_sims = 100
p_vals = ...
n_sds = 10
# you can use the values you chose in the last simulation as a guide for what to choose here
pop_sds = seq(...) 

# These were the sample sizes in the walkthrough simulation.  you may want to try a different range.
sample_sizes = seq(10, 50)

sim_output_3 = matrix(nrow = length(pop_sds), ncol = length(sample_sizes))

for(k in 1:length(pop_sds))
{
  pop_sd_k = pop_sds[k]
  for(j in 1:length(sample_sizes))
  {
    x_vals = ...
    
    for(i in 1:n_sims)
    {
      fit_sim = linear_sim_fit(...)
      p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
    }
    sim_output_3[k, j] = sum(p_vals < alpha) / n_sims
  }
}
image(sim_output_3)
```


## Questions




```{r sd_size_sim_2, echo=FALSE, eval = FALSE}
alpha = 0.05
n_sims = 50
p_vals = numeric(n_sims)
n_sds = 10
pop_sds = seq(from = 0.1, to = 1.5, length.out = n_sds)
sample_sizes = seq(10, 50)

sim_output_3 = matrix(nrow = length(pop_sds), ncol = length(sample_sizes))

for(k in 1:length(pop_sds))
{
  pop_sd_k = pop_sds[k]
  for(j in 1:length(sample_sizes))
  {
    x_vals = seq(0, 100, length.out = sample_sizes[j])
    
    for(i in 1:n_sims)
    {
      fit_sim = linear_sim_fit(
        x = x_vals,
        y_int = int_obs,
        slope = slope_obs,
        st_dev = pop_sd_k
      )
      p_vals[i] = summary(fit_sim)$coefficients[2, 'Pr(>|t|)']
    }
    sim_output_3[k, j] = sum(p_vals < alpha) / n_sims
  }
}
image(sim_output_3)
contour(
  x = pop_sds,
  y = sample_sizes, 
  z = sim_output_3,
  xlab = "population s.d.",
  ylab = "sample size",
  main = "Contour Plot of Statistical Power")
rgl::persp3d(
  x = pop_sds,
  y = sample_sizes, 
  z = sim_output_3,
  col = 'lightblue',
  theta = 30, phi = 30, expand = .75,
  ticktype = 'detailed')
```


```{r persp_plot_interactive_2, echo = FALSE, eval = FALSE}
rgl::persp3d(
  x = pop_sds,
  y = sample_sizes, 
  z = sim_output_3,
  col = 'lightblue',
  theta = 30, phi = 30, expand = .75,
  ticktype = 'detailed')
```
```{r contour_plot_2, echo=FALSE, eval = FALSE}
contour(
  x = pop_sds,
  y = sample_sizes, 
  z = sim_output_3,
  xlab = "population s.d.",
  ylab = "sample size",
  main = "Contour Plot of Statistical Power")
```
